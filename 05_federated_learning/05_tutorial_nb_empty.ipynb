{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c30de9a",
   "metadata": {},
   "source": [
    "# Week 05 – Federated Learning\n",
    "\n",
    "We are using `flwr`, a package for federated learning. You can find the documentation and examples here: https://flower.ai\n",
    "\n",
    "We use the `flwr` tutorial provided here as a basis: https://colab.research.google.com/github/adap/flower/blob/main/examples/flower-in-30-minutes/tutorial.ipynb#scrollTo=7GwQvKl3Mt-b\n",
    "\n",
    "## set up\n",
    "\n",
    "```\n",
    "pip install pandas numpy scikit-learn matplotlib torch torchvision flwr-datasets\n",
    "\n",
    "pip install -U flwr[\"simulation\"]\n",
    "```\n",
    "\n",
    "If you get an error at the last step, try `pip install 'flwr[simulation]'` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccde8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import flwr as fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a8506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc7f0c",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "### Load dataset from `flwr_datasets`\n",
    "\n",
    "In federated learning, each client has its own data partition. We can specify a partitioner and then pass it to the the function `FederatedDataset` from `flwr_datasets` to load the data and create n partitions of it, where n is the number of clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3420e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import IidPartitioner\n",
    "\n",
    "# define the number of clients, i.e. number of partitions\n",
    "NUM_CLIENTS = 100\n",
    "\n",
    "# creater partitioner\n",
    "partitioner = IidPartitioner(num_partitions=NUM_CLIENTS)\n",
    "\n",
    "# partition only the \"train\" split of the MNIST dataset\n",
    "# The MNIST dataset will be downloaded if it hasn't been already\n",
    "fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": partitioner}, seed=42)\n",
    "\n",
    "# get train and test splits\n",
    "train_split = fds.load_split('train')\n",
    "test_split = fds.load_split('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae76557",
   "metadata": {},
   "source": [
    "#### Q: We can use the `test_split` as centralized testset. What is the centralized testset and what is it used for?\n",
    "\n",
    "...\n",
    "\n",
    "#### Q: What does `NUM_CLIENTS = 100` mean?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab0a2ad",
   "metadata": {},
   "source": [
    "### Visualize distribution of training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ceecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# construct histogram\n",
    "all_labels = train_split[\"label\"]\n",
    "all_label_counts = Counter(all_labels)\n",
    "\n",
    "# visualise histogram\n",
    "bar = plt.bar(all_label_counts.keys(), all_label_counts.values())\n",
    "_ = plt.bar_label(bar)\n",
    "\n",
    "# plot formatting\n",
    "_ = plt.xticks([label for label in all_label_counts.keys()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ce008",
   "metadata": {},
   "source": [
    "### Visualize samples from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "def visualise_n_random_examples(trainset_, n: int, verbose: bool = True):\n",
    "    trainset_data = [\n",
    "        Image.open(io.BytesIO(entry[0].as_py())) for entry in trainset_.data[0]\n",
    "    ]\n",
    "    idx = list(range(len(trainset_data)))\n",
    "    random.shuffle(idx)\n",
    "    idx = idx[:n]\n",
    "    if verbose:\n",
    "        print(f\"will display images with idx: {idx}\")\n",
    "\n",
    "    # construct canvas\n",
    "    num_cols = 8\n",
    "    num_rows = int(np.ceil(len(idx) / num_cols))\n",
    "    fig, axs = plt.subplots(figsize=(16, num_rows * 2), nrows=num_rows, ncols=num_cols)\n",
    "\n",
    "    # display images on canvas\n",
    "    for c_i, i in enumerate(idx):\n",
    "        axs.flat[c_i].imshow(trainset_data[i], cmap=\"gray\")\n",
    "\n",
    "visualise_n_random_examples(train_split, n=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503dbf5",
   "metadata": {},
   "source": [
    "### Plot data distribution for n partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could load a single partition like this\n",
    "partition_0 = fds.load_partition(0)\n",
    "partition_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f05d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr_datasets.visualization import plot_label_distributions\n",
    "\n",
    "fig, ax, df = plot_label_distributions(\n",
    "    partitioner,\n",
    "    label_name=\"label\",\n",
    "    plot_type=\"bar\",\n",
    "    size_unit=\"absolute\",\n",
    "    partition_id_axis=\"x\",\n",
    "    legend=True,\n",
    "    verbose_labels=True,\n",
    "    max_num_partitions=30,  # nr of partitions to visualize\n",
    "    title=\"Per Partition Labels Distribution\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194bbbb",
   "metadata": {},
   "source": [
    "### Define function to transform and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d21171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "def get_mnist_dataloaders(train_set, test_set, batch_size: int):\n",
    "    pytorch_transforms = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    # Prepare transformation functions\n",
    "    def apply_transforms(batch):\n",
    "        batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
    "        return batch\n",
    "\n",
    "    mnist_train = train_set.with_transform(apply_transforms)\n",
    "    mnist_test = test_set.with_transform(apply_transforms)\n",
    "\n",
    "    # Construct PyTorch dataloaders\n",
    "    trainloader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "    testloader = DataLoader(mnist_test, batch_size=batch_size)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# Construct dataloaders\n",
    "trainloader, testloader = get_mnist_dataloaders(train_split, test_split, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c3cc7",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "### Define the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714b2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76929c5c",
   "metadata": {},
   "source": [
    "#### Q: How many layers does this network have? \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a87d7f",
   "metadata": {},
   "source": [
    "### Define functions to train model\n",
    "\n",
    "These functions will be needed later on by each client when they fit the model locally on their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "928a7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, epochs, device=\"cpu\"):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    net.to(device)\n",
    "    net.train()\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def test(net, testloader, device):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, loss = 0, 0.0\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75035e",
   "metadata": {},
   "source": [
    "# The client\n",
    "\n",
    "In federated learning we have multiple clients that each own some data and train a model locally with this data. \n",
    "\n",
    "\n",
    "### Defining the Flower Client \n",
    "\n",
    "A Flower Client is a simple Python class with two methods:\n",
    "\n",
    "* `fit()`: With this method, the client does on-device training for a number of epochs using its own data. \n",
    "\n",
    "* `evaluate()`: With this method, the server can evaluate the performance of the global model on the local validation set of a client. \n",
    "\n",
    "\n",
    "In addition, we specify two helper functions:\n",
    "* `set_params()`: This method takes the parameters sent by the server and uses them to initialise the parameters of the local model that is ML framework specific (e.g. TF, Pytorch, etc).\n",
    "\n",
    "* `get_params()`: It extracts the parameters from the local model and transforms them into a list of NumPy arrays. This ML framework-agnostic representation of the model will be sent to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32bfbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from flwr.common import NDArrays, Scalar\n",
    "from flwr.client import NumPyClient\n",
    "\n",
    "\n",
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, trainloader, valloader) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.model = Net(num_classes=10)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"This method trains the model using the parameters sent by the\n",
    "        server on the dataset of this client. At then end, the parameters\n",
    "        of the locally trained model are communicated back to the server\"\"\"\n",
    "\n",
    "        # copy parameters sent by the server into client's local model\n",
    "        set_params(self.model, parameters)\n",
    "\n",
    "        # read from config\n",
    "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
    "\n",
    "        # Define the optimizer\n",
    "        optim = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "        # do local training (call same function as centralised setting)\n",
    "        train(self.model, self.trainloader, optim, epochs, self.device)\n",
    "\n",
    "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
    "        return get_params(self.model), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
    "        \"\"\"Evaluate the model sent by the server on this client's\n",
    "        local validation set. Then return performance metrics.\"\"\"\n",
    "\n",
    "        set_params(self.model, parameters)\n",
    "        # do local evaluation (call same function as centralised setting)\n",
    "        loss, accuracy = test(self.model, self.valloader, self.device)\n",
    "        # send statistics back to the server\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}\n",
    "\n",
    "# Two auxhiliary functions to set and extract parameters of a model\n",
    "def set_params(model, parameters):\n",
    "    \"\"\"Replace model parameters with those passed as `parameters`.\"\"\"\n",
    "\n",
    "    params_dict = zip(model.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(v) for k, v in params_dict})\n",
    "    # now replace the parameters\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_params(model):\n",
    "    \"\"\"Extract model parameters as a list of NumPy arrays.\"\"\"\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af277c61",
   "metadata": {},
   "source": [
    "### Assigning partition of the data to a client\n",
    "\n",
    "Each client has it's own partition of the data. We already specified in the beginning the nr of partitions we need. With this function we can load the partitions and assign them to a client. We also make use of the dataloaders we defined in the beginning to correctly load and transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a30a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import Context\n",
    "from flwr.client import ClientApp\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    \"\"\"Returns a FlowerClient containing its data partition.\"\"\"\n",
    "\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    partition = fds.load_partition(partition_id, \"train\")\n",
    "    # partition into train/validation\n",
    "    partition_train_val = partition.train_test_split(test_size=0.1, seed=42)\n",
    "    trainset = partition_train_val[\"train\"] \n",
    "    valset = partition_train_val[\"test\"]\n",
    "\n",
    "    # Let's use the function defined earlier to construct the dataloaders\n",
    "    # and apply the dataset transformations\n",
    "    trainloader, testloader = get_mnist_dataloaders(trainset, valset, batch_size=32)\n",
    "\n",
    "    return FlowerClient(trainloader=trainloader, valloader=testloader).to_client()\n",
    "\n",
    "\n",
    "# Concstruct the ClientApp passing the client generation function\n",
    "client_app = ClientApp(client_fn=client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c621b5",
   "metadata": {},
   "source": [
    "## Aggregation strategy – Federated Averaging\n",
    "\n",
    "\n",
    "The core steps of federated learning are sampling clients, sending the global model to the clients so they can run `fit()` locally on their training data, receive updated models from each client, aggregate these models to construct a new global model, evaluate model.\n",
    "\n",
    "There are different ways to aggregate all the model updates received from the clients. The probably most well-known is _federated averaging_, see the paper by [McMahan et al. (2016)](https://arxiv.org/abs/1602.05629) for more details.\n",
    "\n",
    "We need to define the strategy used for aggregation in `flwr`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f457c3",
   "metadata": {},
   "source": [
    "### Function to evaluate on centralized test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99710006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_fn(testloader):\n",
    "    \"\"\"Return a function that can be called to do global evaluation. In other words, this function will\n",
    "    be executed by the strategy at the end of each round to evaluate the state of the global model.\"\"\"\n",
    "\n",
    "    # Evaluate global model on the whole test set\n",
    "    def evaluate_fn(server_round: int, parameters, config):\n",
    "        \"\"\"This function is executed by the strategy it will instantiate a model and replace its \n",
    "        parameters with those from the global model. Then, the model will be evaluate on the test\n",
    "        set (recall this is the whole MNIST test set).\"\"\"\n",
    "\n",
    "        model = Net(num_classes=10)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        # set parameters to the model\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "        # call test (evaluate model as in centralised setting)\n",
    "        loss, accuracy = test(model, testloader, device)\n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "    return evaluate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b425bb",
   "metadata": {},
   "source": [
    "### Extra functionality\n",
    "\n",
    "We are writing two functions – (1) `fit_config()` where we can configure how clients do local training (we can specify nr of epochs, learning rate, etc.), and (2) `weighted_average()` which aggregates the performance metrics (accuracy in this case) that the clients return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0b6c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from flwr.common import Metrics\n",
    "\n",
    "def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
    "    \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
    "    config = {\n",
    "        \"epochs\": 1,  # Number of local epochs done by clients\n",
    "        \"lr\": 0.01,  # Learning rate to use by clients during fit()\n",
    "    }\n",
    "    return config\n",
    "\n",
    "# Define metric aggregation function\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
    "    the client's evaluate() method.\"\"\"\n",
    "    # multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718855a1",
   "metadata": {},
   "source": [
    "We'll use these functions when defining the strategy in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca9b19",
   "metadata": {},
   "source": [
    "### The `server_fn` callback\n",
    "\n",
    "The easiest way to create a `ServerApp` with the aggregation _strategy_ of your choice is by means of a `server_fn` callback. It has a similar signature to `client_fn` but, instead of returning a client object, it returns all the components needed to run the server-side logic in Flower. Inside `server_fn` we'll define the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed0f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import ndarrays_to_parameters\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "# let's run the simulation for 10 rounds\n",
    "num_rounds = 20\n",
    "\n",
    "def server_fn(context: Context):\n",
    "\n",
    "    # instantiate the model\n",
    "    model = Net(num_classes=10)\n",
    "    ndarrays = get_params(model)\n",
    "    # convert model parameters to flwr.common.Parameters\n",
    "    global_model_init = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "    # Define the strategy\n",
    "    strategy = FedAvg(\n",
    "        # num_rounds=num_rounds,\n",
    "        fraction_fit=0.1,  # 10% clients sampled each round to do fit()\n",
    "        fraction_evaluate=0.05,  # 5% clients sample each round to do evaluate()\n",
    "        on_fit_config_fn=fit_config, # configuration for clients\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics using weighted average as defined earlier\n",
    "        initial_parameters=global_model_init,  # initialised global model\n",
    "        evaluate_fn=get_evaluate_fn(testloader),  # gloabl evaluation on centralized test set\n",
    "    )\n",
    "\n",
    "    # Construct ServerConfig\n",
    "    config = ServerConfig(num_rounds=num_rounds)\n",
    "\n",
    "    # Wrap everything into a `ServerAppComponents` object\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "# Create your ServerApp\n",
    "server_app = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91133855",
   "metadata": {},
   "source": [
    "# Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.simulation import run_simulation\n",
    "\n",
    "run_simulation(\n",
    "    server_app=server_app, \n",
    "    client_app=client_app, \n",
    "    num_supernodes=NUM_CLIENTS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b539a8d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec41c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy/paste from printed output\n",
    "results_centralized = {'accuracy': [(0, 0.1102),\n",
    "(1, 0.2403),\n",
    "(2, 0.3805),\n",
    "(3, 0.3576),\n",
    "(4, 0.5578),\n",
    "(5, 0.7339),\n",
    "(6, 0.795),\n",
    "(7, 0.8559),\n",
    "(8, 0.887),\n",
    "(9, 0.9022),\n",
    "(10, 0.898),\n",
    "(11, 0.9174),\n",
    "(12, 0.9138),\n",
    "(13, 0.926),\n",
    "(14, 0.9292),\n",
    "(15, 0.9348),\n",
    "(16, 0.9401),\n",
    "(17, 0.9423),\n",
    "(18, 0.945),\n",
    "(19, 0.9506),\n",
    "(20, 0.9516)]}\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Extract rounds and accuracy values\n",
    "rounds_centralized = [item[0] for item in results_centralized['accuracy']]\n",
    "global_accuracy_centralised = [item[1] for item in results_centralized['accuracy']]\n",
    "\n",
    "# plot centralized accuracy scores\n",
    "acc = [100.0 * data for data in global_accuracy_centralised] # scores\n",
    "plt.plot(rounds_centralized, acc)\n",
    "\n",
    "# axis labels & title\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.title(f\"MNIST -- {NUM_CLIENTS} clients with 10 clients per round\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5f318",
   "metadata": {},
   "source": [
    "#### Q: Explain what can be seen in the plot. \n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week5_test",
   "language": "python",
   "name": "week5_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
